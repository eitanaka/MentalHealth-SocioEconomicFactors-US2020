---
title: "Lifecycle and mental health"
author: "Ishani Makwana, Henry Hirsch and Ei Tanaka"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: hide
    number_sections: false
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '3'
---
```{r setup, include=FALSE}
# Some of common RMD options (and the defaults) are: 
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right', 
knitr::opts_chunk$set(warning = F, results = "hide", message = F)
# Can globally set option for number display format.
options(scientific=T, digits = 3) 
# options(scipen=9, digits = 3) 
```
Loading all the necessary libraries which are needed for this project.
A brief explanation of each of the libraries used in this R Markdown script:

## Abstract
This research project aimed to identify the factors associated with depression and poor mental health rates in the United States. The study analyzed data from multiple sources, including the Behavioral Risk Factor Surveillance System, American Community Survey, and COVID-19 Community Profile Report. The data were used to build multiple linear regression models and regression trees and conduct stepwise selection to identify the optimal combination of features. The study found that demographic, socioeconomic, and health-related variables significantly predict depression and poor mental health rates. The models can serve as a basis for further research on this topic and assist policymakers in identifying high-risk populations and designing targeted interventions. However, the study has limitations such as the possibility of measurement bias, limited geographical areas, and not accounting for potential confounding variables. Further research could explore additional factors related to depression and conduct qualitative research to understand better the subjective experiences of individuals living with depression. Overall, this study provides insights into the factors associated with depression and poor mental health rates in the United States and can inform future research and policy decisions.
 
```{r}
rm(list=ls())
library(readr)
library(ggplot2)
library(ggpubr)
library(tidyr)
library(corrplot)
library(ezids)
library(car)
library(rpart)
library(rpart.plot)
library(rattle)
library(tree)
```

```{r init}
url <- 'https://raw.githubusercontent.com/eitanaka/DATS6101_Final_Project_Team2/main/data_set/geo_socio_health_df.csv'
master_df<- read_csv(url)
master_df <- master_df[,-1]
```

```{r rename}
# To rename some columns in a data frame to make them more readable and easier to work with.This is done by using the "colnames" function to first select the column names that match the original names, and then assigning new names.
colnames(master_df)[colnames(master_df) == "MT_Never Married"] <- "mt.nev.mar"
colnames(master_df)[colnames(master_df) == "MT_Now married"] <- "mt.now.mar"
colnames(master_df)[colnames(master_df) == "Total Population"] <- "tot.pop"
colnames(master_df)[colnames(master_df) == "EA_Less than high school graduate"] <- "ea.less.hs.deg"
colnames(master_df)[colnames(master_df) == "EA_High school graduate"] <- "ea.hs.deg"
colnames(master_df)[colnames(master_df) == "EA_college or associate's degree"] <- "ea.col.ass.deg"
colnames(master_df)[colnames(master_df) == "EA_Bachelor's degree"] <- "ea.ba.deg"
colnames(master_df)[colnames(master_df) == "EA_Graduate or professional degree"] <- "ea.grad.prof.deg"
```

```{r}
# Create a new data only including numerical variable
numeric_vars <- sapply(master_df, is.numeric)
num_df <- master_df[, numeric_vars]
```

## 1. Introduction
Using a range of datasets, our previous project focused on the relationship between health risk behaviors: lack of physical activity and sleep, and health outcomes (depression) and status (poor mental health). In this research project, we investigate the influence of other health conditions, socioeconomic factors, and the economic impact of covid-19 on mental health in the United States. We aim to determine which factors significantly impact mental health and well-being in the US during 2020. To do so, we will analyze four different datasets at the census tract level, utilizing various statistical techniques such as correlation, linear regression, and decision tree analysis. The results of this study have important implications for improving mental health outcomes and shaping public health policies and interventions. We can develop targeted interventions and programs to address these issues by identifying the factors that most significantly impact mental health. 

### 1.1. Data Sets Descritption
Our research project utilizes four different datasets to investigate the influence of health conditions, socioeconomic factors, and the economic impact of COVID-19 on mental health outcomes in the United States. One of these datasets is from our previous project (Project 1), while the other is collected specifically for this study.

1. CDC_PLACE dataset measures health outcomes, prevention, health risk behaviors, and health status. This dataset contains 13 health outcomes, nine prevention measures, four health risk behaviors, and three health status measures. The original dataset was launched by the Centers for Disease Control and Prevention (CDC)- In 2020, the dataset provided small area estimates for counties, places, census tracts, and ZIP Code Tabulation Areas across the United States. Each measure has a comprehensive definition that includes the background, significance, limitations of the indicator, data source, and limitations of the data resources.

2. The American Community Survey 2020 is another dataset used in our study. This ongoing survey provides detailed information on the population and housing in the US yearly. The ACS  helps local officials, community leaders, and businesses understand the changes in their communities.    Through the ACS, we know more about jobs and occupations, educational attainment, veterans, whether people own or rent their homes, and other topics. 


3. Planning Database 2020 contains operational, demographic, and socioeconomic statistics from the 2010 Census at both the tract and block group levels.CEII data also includes annualized monthly estimates of county-level value added for over 100 industries. Counties with economic activities dominated by industries experiencing rising unemployment can expect more enormous direct impacts on their local economies, notably if the industries account for a large portion of the economic output of that county.

4. County Economic Impact Index 2020 estimates the overall county-level economic activity change during the COVID-19 pandemic relative to 2020. These four datasets and the six others were analyzed to investigate the relationship between mental health outcomes and various socioeconomic and lifestyle factors, as well as the impact of COVID-19.

### 1.2. Research / SMART Questions

Our guiding questions for this project are the following:

**SQ1: What factors do we observed highly associated with depression and poor mental health rates?**

**SQ 2: Using those factors, how accurately can we infer depression and poor mental health rates in a given tract?**

### 1.3. Data Preparation
Data cleaning and preparation is a crucial step in any data analysis project. In this step, we ensure that the data is in a format suitable for analysis and that any inconsistencies, errors, or missing values are corrected or removed. Our project merged the four data sources by countyFIPs and Tract level Geographical ID. This allowed us to combine information from different sources based on their standard identifiers. We also renamed variables to make them more meaningful and easier to understand. After merging and renaming variables, we removed all rows, including null values. This was important because null values could interfere with our analysis and lead to inaccurate conclusions. We also eliminated all outliers to reduce the influence of extreme values on our analysis. Once we completed these cleaning steps, we had a data frame with 12,444 observations of 57 variables. This data frame was ready for further analysis and exploration.

## 2. EDA
In this section, we perform EDA on a dataset containing health and socioeconomic factors for different tracts in the United States. The purpose of the analysis is to investigate the relationship between these factors and two health outcomes: depression rate and poor mental health rate. We check the data quality, including missing values, outliers, and inconsistencies. We then examine the distributions of the variables and their relationships using visualizations such as histograms, scatterplots, and correlation matrices. The EDA reveals that some variables are highly correlated with depression rates and poor mental health rates. Overall, the EDA helps us to understand the data, identify potential issues, and guide our subsequent analysis. The insights gained from this analysis have important implications for public health policy and model building.

### 2.1. Data Structure & Data Types
    The data structure of the dataset is a table with 60,682 rows and 57 columns. The columns represent various variables, including health indicators, demographic characteristics, and economic indicators. The data types of the variables are numeric, except for CountyFIPS, GEOID, StateAbbr, and CountyName. The dataset has also omitted some rows due to missing data, as indicated by the "na. action" attribute. The dataset is a comprehensive health and demographic information collection for a large population.
```{r echo=T, eval=T, include=T, results='markup', colapse=T}
str(num_df)
```

### 2.2. Summary Statistics  

The table displays the summary statistics of various health and socioeconomic indicators in 2020. The mean values for several health indicators, such as depression and obesity, are high, indicating potential health concerns in the population. Education levels vary, with 12.2% having less than a high school degree and 28.8% having some college or associate's degree. The poverty rate is 15.3%, and 9.1% of the population does not have health insurance. Additionally, 13.3% of households do not have a computer, and 28.1% of individuals live alone.

```{r echo=T, eval=T, include=T, results='markup', colapse=T}
summary(num_df)
```

### 2.3. Handle Null Values

When we check for null values, we confirm that there are null values in the data set in the following table. We then confirmed that they were a small number relative to the overall data, so we removed them all. To remove rows with null values in the columns listed below, we use the "na.omit" function. This function removes rows with any missing values in the specified columns. After removing the rows with null values, the resulting dataset only contains rows with complete data in the specified columns.

```{r echo=T, eval=T, results='markup'}
colSums(is.na(num_df))
num_df <- na.omit(num_df)
```

### 2.4. Check for and remove outliers

Next, we are handling outliers in the numerical data. We apply the outlierKD2 function from the "ezids" package to detect and remove the outliers in the dataset. We loop through all columns and remove outliers in each column by calling the outlierKD2 function. We remove any resulting NAs and update the data frame after each column. Finally, we remove the last two columns, which are added by outlierKD2. Handling outliers is essential in creating an accurate model because outliers can significantly impact the results, especially in regression models, and can lead to poor performance and inaccurate predictions.
     
```{r}
new_num_df <- outlierKD2(num_df, num_df[[1]], rm=TRUE, boxplt=F, histogram=F,qqplt=F)
new_num_df <- new_num_df[,1:(ncol(new_num_df)-2)]

# loop through all columns
for (col_name in colnames(num_df)[2:ncol(num_df)]) {
  # remove outliers
  new_num_df <- outlierKD2(new_num_df, new_num_df[[col_name]], rm=T, boxplt=F, histogram=F,qqplt=F)
  new_num_df <- na.omit(new_num_df)
  new_num_df <- new_num_df[,1:(ncol(new_num_df)-2)]
}
new_num_df <- new_num_df[,1:(ncol(new_num_df)-1)]
```

### 2.5. Boxplot Analysis

The box plots show the distribution of various health, demographic, and socioeconomic factors. The plots suggest that obesity, diabetes, and depression rates are relatively high, while education levels and median household income are moderate. Looking at the distribution of all variables, it was confirmed that the distribution was relatively normal, thanks to removing outliers.
  
```{r include=T, echo=T, eval=T, results='markup'}
par(mfrow=c(8, 8))
par(mar=c(1, 1, 1, 1))
for (i in 1:ncol(new_num_df)) {
  boxplot(new_num_df[[i]], main=names(new_num_df)[i])
}
```

### 2.6. Scatter plot

We create scatter plots to visualize the relationship between depression and other variables, poor mental health, and other variables. The scatter plots show the distribution of each variable and the trend of the relationship between the variables. The data used in the plots come from a survey that collected information on various demographic, socioeconomic, and health-related factors. 

#### 2.6.1. Scatter plot for depression

Based on the scatter plot analysis of depression, it appears that depression is positively associated with "OBESITY," "PHLTH," and "ea.hs.deg." On the other hand, there seems to be a negative association between depression and "MI_Estimate," "ea.grad.prof.deg," "CT_>60," and "had.broad," indicating that as these variables increase, the level of depression decreases. The strength of these associations varies, with "OBESITY," "PHLTH," and "MI_Estimate" having relatively stronger positive correlations with depression, while "ea.hs.deg" and "ea.grad.prof.deg" have weaker negative correlations.
  
```{r include=T, echo=T, eval=T, results='markup'}
theme_set(theme_pubr(base_size = 3.5))
plot_list <- list()
for (col in names(new_num_df)) {
  if (col != "DEPRESSION") {
    plot_data <- data.frame(x = new_num_df[[col]], y = new_num_df$DEPRESSION)
    plot <- ggplot(plot_data, aes(x = x, y = y)) + 
      geom_point(size=0.3) +
      geom_smooth(method = "lm", se = FALSE) +
      xlab(col) +
      theme(legend.position = "none")
    plot_list[[col]] <- plot
  }
}
ggarrange(plotlist = plot_list, ncol = 7, nrow = 8)
```

#### 2.6.2. Scatter plot for poor mental heealht

The scatter plots with a fitted line for poor mental health (MHLTH) and the above highly correlated variables show that MHLTH positively correlates with PHLTH, OBESITY, and poverty. The scatter plot for PHLTH and MHLTH shows a clear positive linear relationship.

```{r include=T, echo=T, eval=T, results='markup'}
# Scatter plots with fit line for mhlth and other dependent variables
theme_set(theme_pubr(base_size = 3.5))
plot_list <- list()
for (col in names(new_num_df)) {
  if (col != "MHLTH") {
    plot_data <- data.frame(x = new_num_df[[col]], y = new_num_df$MHLTH)
    plot <- ggplot(plot_data, aes(x = x, y = y)) + 
      geom_point(size=0.3) +
      geom_smooth(method = "lm", se = FALSE) +
      xlab(col) +
      theme(legend.position = "none")
    plot_list[[col]] <- plot
  }
}
ggarrange(plotlist = plot_list, ncol = 7, nrow = 8)
```

### 2.7. Distribution of dependent variable

Next, we aim to determine the distribution of the dependent variables, depression rate, and poor mental health rate, to confirm which model would be appropriate for further analysis. The results showed that both depression and poor mental health rates were bell-shaped, indicating a normal distribution. This was confirmed through histograms and Q-Q plots, with both variables showing a close-to-straight-line pattern.
The normal distribution of the dependent variables meets the assumption of linear regression, indicating that a linear regression model can be used for further analysis. This finding is significant as it allows for the exploration of the relationship between the dependent variables and the independent variables.
Using linear regression can provide valuable insight into potential risk factors for depression and poor mental health, allowing for the development of targeted interventions to improve mental health outcomes. 

```{r include=T, echo=T, eval=T, results='markup'}
# Histograms
hist(new_num_df$DEPRESSION, main = "Distribution of Tract-level Depression Rates")

hist(new_num_df$MHLTH, main = "Distribution of Tract-level Poor Mental Health Rates")

```

```{r include=T, echo=T, eval=T, results='markup'}
# QQ plots for the distribution of tract-level depression rates and tract-level poor mental health rates.

qqnorm(new_num_df$DEPRESSION, main = "Distribution of Tract-level Depression Rates")
qqline(new_num_df$DEPRESSION)

qqnorm(new_num_df$MHLTH, main = "Distribution of Tract-level Poor Mental Health Rates")
qqline(new_num_df$MHLTH)
```

### 2.8. Correlations Test

We begin the process of selecting variables for our multiple linear regressions by generating correlation matrices for all of our health and socioeconomic variables. Doing this enables us to select only variables significantly associated with depression or poor mental health rates. We use a 0.35 Pearson's correlation coefficient to generate both correlation matrices. Numerous moderate associations are revealed by doing this. However, it is notable that the associations with poor mental health are more robust than the associations with depression. The variables associated with depression all have correlation coefficients of |+- 0.35| or greater, while those associated with poor mental health all have correlation coefficients of |+- 0.55| or greater. Both health conditions are associated with some combination of health and socioeconomic variables. 

```{r include=T, echo=T, eval=T, results='markup'}
# Create a correlation matrix
cor_matrix <- cor(new_num_df)

# Create two lists which have the names of variables highly correlated (more then 0.3 or less than -0.3)
high_dep_cor_list <- names(which(cor_matrix["DEPRESSION",] > 0.35 | cor_matrix["DEPRESSION",] < -0.35))
high_mhlth_cor_list <- names(which(cor_matrix["MHLTH",] > 0.5 | cor_matrix["MHLTH",] < -0.5))

high_dep_cor_list <- high_dep_cor_list[high_dep_cor_list != "MHLTH"]
high_mhlth_cor_list <- high_mhlth_cor_list[high_mhlth_cor_list != "DEPRESSION"]

# Create two correlation matrixes from new_num_df in the above lists
high_dep_cor_mat <- cor(new_num_df[high_dep_cor_list])
high_mhlth_cor_mat <- cor(new_num_df[high_mhlth_cor_list])

# Plot above correlation matrix
corrplot(high_dep_cor_mat, type = "lower", outline.color = "white", 
           colors = c("#6D9EC1", "white", "#E46726"), legend.title = "Correlation", 
           ggtheme = theme_gray, title = "Highly Correlated Variables with DEPRESSION")

corrplot(high_mhlth_cor_mat, type = "lower", outline.color = "white", 
           colors = c("#6D9EC1", "white", "#E46726"), legend.title = "Correlation", 
           ggtheme = theme_gray, title = "Highly Correlated Variables with mhlth")

my_col <- colorRampPalette(c("red", "white", "blue"))(30)

corrplot(high_dep_cor_mat, method = "number", type = "lower", order = "hclust", diag = FALSE, tl.col = "black", tl.cex = 0.8, cl.cex = 0.8, addCoef.col = "black", col = my_col, main = "", mar = c(0,0,0,0))

corrplot(high_mhlth_cor_mat, method = "number", type = "lower", order = "hclust", diag = FALSE, tl.col = "black", tl.cex = 0.8, cl.cex = 0.8, addCoef.col = "black", col = my_col, main = "", mar = c(0,0,0,0))
```

### 2.9. VIF Test for Multicollinearity
Next, we check the selected variables for multicollinearity by using a Variance Inflation Factor (VIF) test. If multiple independent variables have a multicollinear relationship, we cannot use them for our multiple regressions. Fortunately, all of our selected independent variables have VIF values below 5 (except for LPA with MHLTH, VIF value of 5.02). This means that there is little multicollinearity between our independent variables, and we can use them all in our subsequent multiple regressions. 

```{r include=T, echo=T, eval=T, results='markup'}
calculate_VIF <- function(data, target_col) {
  X <- data[, !colnames(data) %in% target_col]
  vif <- data.frame(
    Feature = colnames(X),
    VIF = apply(X, 2, function(x) vif(lm(x ~ ., data=X)))
  )
  return(vif)
}

depression_VIF <- calculate_VIF(new_num_df[high_dep_cor_list], "DEPRESSION")

mhlth_VIF <- calculate_VIF(new_num_df[high_mhlth_cor_list], "MHLTH")

depression_VIF
mhlth_VIF
```

### 2.10. Feature Selection

After going through this initial testing, we are left with seven variables for our depression regression [Obesity (%), Poor Physical health >= 14 days(%), (Last Academic Record) High School Graduate (%), (Academic Record) Graduate or professional degree (%), Median Income (US dollar), Commute Time >= 60 mins (%), and Broadband access (%] and eight variables for our poor mental health regression [Lack of Physical Activity (%), Obesity (%), Poor Physical health >= 14 days(%), Poor Sleep >= 14 days (%), (Last Academic Record) High School Graduate (%), (Academic Record) Graduate or professional degree (%), Median Income (US$), and Below Poverty Level (%)]. 

```{r include=T, echo=T, eval=T, results='markup'}
dep_features_list <- high_dep_cor_list[high_dep_cor_list != "DEPRESSION"]
mhlth_features_list <- high_mhlth_cor_list[high_mhlth_cor_list != "MHLTH"]

dep_features_list
mhlth_features_list
```

## 3. Model Building

### 3.1. Training and Test Sets
At this point, we split our initial data set into training and testing data sets. We "train" our multiple linear regressions and regression trees on this training set. We then test whether our models are over or underfit by feeding the testing data set into them and comparing the results to the output we got from feeding the initial training data into them.

```{r}
library(caret)
set.seed(123)
fold <- floor(runif(nrow(new_num_df),1,11)) 
  new_num_df$fold <- fold
  
test.set <- new_num_df[new_num_df$fold == 1,] 
train.set <- new_num_df[new_num_df$fold != 1,] 
```

### 3.2. Multiple Linear Regressio

#### Model 1: With Highly correlated variables (Health Factors + Socioeconomic Factors)
```{r}
# multiple linear regression model for depression
depression_model_1 <- lm(DEPRESSION ~ OBESITY + PHLTH + ea.hs.deg + ea.grad.prof.deg + MI_Estimate + `CT_>60` + hhd.broad, data = train.set)

# multiple linear regression model for poor mental health
mhlth_model_1 <- lm(MHLTH ~ LPA + OBESITY + PHLTH + SLEEP + ea.hs.deg + ea.ba.deg + ea.grad.prof.deg + MI_Estimate + poverty, data = train.set)

summary(depression_model_1)
summary(mhlth_model_1)

plot(depression_model_1)
plot(mhlth_model_1)
```

#### Model 2: With Highly correlated health related variables
```{r}
# multiple linear regression model for depression
depression_model_2 <- lm(DEPRESSION ~ OBESITY + PHLTH, data = train.set)

# multiple linear regression model for poor mental health
mhlth_model_2 <- lm(MHLTH ~ LPA + OBESITY + PHLTH + SLEEP, data = train.set)

summary(depression_model_2)
summary(mhlth_model_2)

plot(depression_model_2)
plot(mhlth_model_2)
```

#### Model 3: With Highly correlated socioeconomic related variables
```{r}
# multiple linear regression model for depression
depression_model_3 <- lm(DEPRESSION ~ ea.hs.deg + ea.grad.prof.deg + MI_Estimate + `CT_>60` + hhd.broad, data = train.set)

# multiple linear regression model for poor mental health
mhlth_model_3 <- lm(MHLTH ~ ea.hs.deg + ea.ba.deg + ea.grad.prof.deg + MI_Estimate + poverty, data = train.set)

summary(depression_model_3)
summary(mhlth_model_3)

plot(depression_model_3)
plot(mhlth_model_3)
```

#### 3.2.1. Model Comparison (ANOVA)
We experiment with three different multiple linear regressions and compare their performance using Analysis of Variance (ANOVA) testing. The first of these regressions (Model 1) predicts depression and poor mental health rates by incorporating all of the highly correlated Barbies (for each condition) into the regressions. The second regression (Model 2) only uses a cluster of highly correlated health variables to predict depression and poor mental health rates. Furthermore, finally, the third regression (Model 3) uses a cluster of highly correlated socioeconomic variables to predict depression and poor mental health rates. 

Naturally, Model 1 performs the best overall, incorporating the most significant number of highly correlated variables. In addition, it has a lower residual sum of squares (RSS) than the other models, indicating that it fits the data best and that there is the least amount of unexplained error in the dependent variable variation when using Model 1. In other words, Model 1 can explain more of the variation in depression and mental health rates than the other two models. 

Nevertheless, we are more interested in comparing the performance of Model 2 to Model 3. This comparison shows that Model 2 (the health variables model) performs slightly better than Model 3 (the socioeconomic variables model). While they have RSS values close to one another, Model 2 has a lower degree of freedom (it uses fewer variables in the regression). This is good. Achieving similar predictive accuracy with fewer variables means you have likely isolated some key predictive variables. The ANOVA test shows that the difference between Model 2 and the other models is statistically significant at the 1% level (p-value less than 0.01). In sum, although it is better to incorporate both the highly correlated health variables and the highly correlated socioeconomic variables, the health variables seem more predictive than the socioeconomic variables.

```{r include=T, echo=T, eval=T, results='markup'}
# Perform two-way ANOVA test
depression_anova_model <- anova(depression_model_1, depression_model_2, depression_model_3)
mhlth_anova_model <- anova(mhlth_model_1, mhlth_model_2, mhlth_model_3)


xkabledply(depression_anova_model)
xkabledply(mhlth_anova_model)

# health.socioecon.dep.anova <- anova(depression_model_2, depression_model_3)
# health.socioecon.mhlth.anova <- anova(mhlth_model_2, mhlth_model_3)
# 
# xkabledply(health.socioecon.dep.anova)
# xkabledply(health.socioecon.mhlth.anova)
```

#### 3.2.2 Stepwise Selection (Tuning Multiple Linear Regression Model)

In the initial model, we included all variables with high correlation coefficients. However, the stepwise model identified a smaller set of predictor variables that are highly significant in predicting depression and poor mental health rates. We performed a stepwise model using the AIC criterion to identify the optimal combination of features. AIC accounts for the number of parameters in the model, which helps to prevent overfitting and avoid overly complex models. 
  
```{r}
# Perform stepwise selection using AIC as the selection criterion
depression_stepwise_model <- step(depression_model_1, direction = "both", trace = 0, k = log(nrow(train.set)), criterion = "AIC")

mhlth_stepwise_model <- step(mhlth_model_1, direction = "both", trace = 0, k = log(nrow(train.set)), criterion = "AIC")
```

#### 3.2.3. Best Model vs. Stepwise Model

The stepwise model had fewer variables and demonstrated similar performance as the initial model when compared using an ANOVA test. The residual sum of squares (RSS) for the depression and poor mental health models were almost identical. Therefore, we chose the stepwise model over the initial model as it was more parsimony.
 
```{r include=T, echo=T, eval=T, results='markup'}
dep_anova_model_2 <- anova(depression_model_1, depression_stepwise_model)
mhlth_anova_model_2 <- anova(mhlth_model_1, mhlth_stepwise_model)

xkabledply(dep_anova_model_2)
xkabledply(mhlth_anova_model_2)
```

#### 3.2.4. Best Model Performance

This section summarizes a summary of the models we considered to be the best performing based on the model selection to date.

For depression rates, our model identified five significant predictor variables: "OBESITY Rate", "Poor physical health", "high school graduate as highest level educational attainment", "CT_>60", and "percent of households interacting with the internet". The model explained 37.6% of the variability in depression levels, which is a moderate amount.
  
For poor mental health rates, our model identified seven significant predictor variables: "LPA", "Obesity", "PHLTH", "Sleep", "ea.graduate", "MI_income", and "poverty". The model explained 67.6% of the variability in poor mental health levels, indicating a strong relationship between the predictor variables and poor mental health.

Overall, our findings suggest that demographic, socio-economic, and health-related variables play a significant role in predicting depression and poor mental health rates in the United States. Our models can serve as a basis for further research on this topic and can assist policymakers in identifying high-risk populations and designing targeted interventions.

```{r}
dep_predictions <- predict(depression_model_1, newdata = test.set)

# calculate the R-squared value
r_squared <- summary(depression_model_1)$r.squared

# calculate the mean squared error (MSE)
mse <- mean((test.set$DEPRESSION - dep_predictions)^2)

# print the results
cat("R-squared:", r_squared, "\n")
cat("MSE:", mse, "\n")

mhlth_predictions <- predict(mhlth_stepwise_model, newdata = test.set)

# calculate the R-squared value
r_squared <- summary(mhlth_stepwise_model)$r.squared

# calculate the mean squared error (MSE)
mse <- mean((test.set$MHLTH - mhlth_predictions)^2)

# print the results
cat("R-squared:", r_squared, "\n")
cat("MSE:", mse, "\n")
```


### 3.3. Regression Tree Model
Add comment here
```{r}
# Building a Regression Tree

# Step 1. Use recursive binary splitting to grow a large tree of depression on the training data
train.dep.tree <- rpart(DEPRESSION ~  ACCESS2 + BINGE + CHECKUP + DIABETES + LPA + OBESITY + PHLTH + SLEEP + STROKE + mt.nev.mar + mt.now.mar + MT_Divorces + MT_Separated + MT_Widowed + ea.less.hs.deg + ea.hs.deg + ea.col.ass.deg + ea.ba.deg + ea.grad.prof.deg + MI_Estimate + tot.pop + `CT_<10` + `CT_10-14` + `CT_15-19` + `CT_20-24` + `CT_25-29` + `CT_30-34` + `CT_35-44` + `CT_45-59` + `CT_>60` + ES_Total_labor_force + ES_Civilian_labor_force + ES_Civilian_labor_force_employed + ES_Civilian_labor_force_unemployed + ES_Armed_Forces + ES_Not_in_labor_force + land + urban + poverty + no.ins + disab + no.comp + `broad&comp` + no.eng + sing.mom + live.alone + pub.assist + no.phone + no.plumb + married.kid + hhd.no.comp + hhd.only.phone + hhd.no.int + hhd.broad + index_apr20, data = train.set, method = "anova")

# Grow large tree of mhlth on the training data 
train.mhlth.tree <- rpart(MHLTH ~ ACCESS2 + BINGE + CHECKUP + DIABETES + LPA + OBESITY + PHLTH + SLEEP + STROKE + mt.nev.mar + mt.now.mar + MT_Divorces + MT_Separated + MT_Widowed + ea.less.hs.deg + ea.hs.deg + ea.col.ass.deg + ea.ba.deg + ea.grad.prof.deg + MI_Estimate + tot.pop + `CT_<10` + `CT_10-14` + `CT_15-19` + `CT_20-24` + `CT_25-29` + `CT_30-34` + `CT_35-44` + `CT_45-59` + `CT_>60` + ES_Total_labor_force + ES_Civilian_labor_force + ES_Civilian_labor_force_employed + ES_Civilian_labor_force_unemployed + ES_Armed_Forces + ES_Not_in_labor_force + land + urban + poverty + no.ins + disab + no.comp + `broad&comp` + no.eng + sing.mom + live.alone + pub.assist + no.phone + no.plumb + married.kid + hhd.no.comp + hhd.only.phone + hhd.no.int + hhd.broad + index_apr20, data = train.set)

# Plot tree model
fancyRpartPlot(train.dep.tree, main = "Depression Rate Tree")
fancyRpartPlot(train.mhlth.tree, main = "Poor Mental Health Rate Tree")

# Print summary
summary(train.dep.tree)
summary(train.mhlth.tree)
```

#### Regression Tree Performance
- Evaluating the model: The model is evaluated using various metrics such as mean squared error (MSE), root mean squared error (RMSE), and R-squared.
- Validating the model: The model is validated using the testing set to assess its ability to generalize to new data.
- Tuning the model: The model is tuned by adjusting the hyperparameters to improve its performance.
- Interpreting the model: The regression tree is interpreted to gain insights into the relationships between the independent variables and the dependent variable.
```{r}
# Generate predicted values for test set
test.set$pred.depression <- predict(train.dep.tree, newdata = test.set)

# Calculate evaluation metrics
MSE <- mean((test.set$DEPRESSION - test.set$pred.depression)^2)
R2 <- 1 - sum((test.set$DEPRESSION - test.set$pred.depression)^2) / sum((test.set$DEPRESSION - mean(test.set$DEPRESSION))^2)

# Print evaluation metrics
cat("R-squared:", R2, "\n")
cat("MSE:", MSE, "\n")

# The R-squared value of 0.399 suggests that the regression tree model explains 39.9% of the variation in the data, which is a moderate level of explanation.
# The MSE (Mean Squared Error) of 6.05 represents the average squared difference between the predicted values and the actual values, with a higher value indicating worse performance.

test.set$pred.mhlth <- predict(train.mhlth.tree, newdata = test.set)
# Calculate evaluation metrics
MSE <- mean((test.set$MHLTH - test.set$pred.mhlth)^2)
R2 <- 1 - sum((test.set$MHLTH - test.set$pred.mhlth)^2) / sum((test.set$MHLTH - mean(test.set$MHLTH))^2)

# Print evaluation metrics
cat("R-squared:", R2, "\n")
cat("MSE:", MSE, "\n")

# The regression tree model with MHLTH as the target variable has an R-squared value of 0.685, indicating that 68.5% of the variability in the MHLTH variable can be explained by the model. 
# The mean squared error (MSE) is 1.07, which means that on average, the model's predictions are off by 1.07 units from the actual values. .
# The root mean squared error (RMSE) is 1.04, which is the same as the standard deviation of the residuals.
# This indicates that the model's predictions have a standard deviation of 1.04 around the actual values. Overall, these metrics suggest that the model has a moderate level of predictive power for the MHLTH variable.
```

## 4. Result
Based on the tests and modeling performed previously, the factors that are highly associated with depression and poor mental health rates are:

Depression: Obesity, poor physical health, high school degree as the highest level of educational attainment, commute time >= 60 min, households without high-speed wireless internet, binge drinking, the economic effect of COVID-19, and no English.
Poor Mental Health: Lack of physical activity, obesity, poor physical health, lack of sleep, BA as highest level educational attainment, graduate or professional degree as the highest level of educational attainment, never married, married with a kid, recent checkup, median income, poverty rate, and binge drinking.
We can infer depression and poor mental health rates in a given tract based on the above factors with some accuracy. For depression, the variation of these factors is slightly associated (r-square: 0.37) with the variation in depression rate. For poor mental health, the variation of these factors is highly associated (r-square: 0.69) with the variation of poor mental health rate.

## 5. Discussion
In this section, we discuss the limitations of our research project and propose potential areas for further research.

### 5.1. Limitations
Based on the information we provided earlier, there are several limitations to this project:
- The measure of the poor mental state over the last two weeks may need to be more precise because the data was combined from different datasets that were gathered more than two weeks apart. This could introduce measurement bias and affect the accuracy of the results.
- The project should have performed pruning or training regression trees, which could have resulted in less accurate models.
- The feature selection process used in the analysis could have been more optimal, which could result in irrelevant or redundant variables being included in the model, reducing its predictive power.
The data used in the analysis may be representative of only some of the population, as it was collected from a specific geographic region or sample size.
- The project was limited to some geographical regions, which may not be representative of the broader population or may have limited the ability to identify additional factors associated with depression and poor mental health.
- The project did not account for potential confounding variables like the impact of cultural or social factors that could influence the relationship between the identified factors and depression or poor mental health, leading to the possibility of overestimating or underestimating the actual effect of these factors, which may be an essential factor to consider in future research. 


### 5.2. Further Research
Some potential further research directions includes:
- Conduct micro-level analysis: Further research could explore the social systems and relationships contributing to depression. This could involve examining individual-level factors, such as social support, family dynamics, and work stress, and how they impact mental health.
- Integrate genetic information and other biological measures, such as hormonal imbalances and brain imaging. There is evidence that genetics play a role in the development of depression. Further research could examine genetic information and other biological factors related to depression.
- Conduct more feature selection methods to identify the most important predictors of depression and poor mental health. As mentioned earlier, the feature selection process used in this project was limited. Further research could involve more sophisticated feature selection methods, such as principal component analysis or regularized regression techniques.
- Explore additional factors: The current analysis focused on a limited set of factors in the dataset. Future research could explore additional factors related to depression, such as regular diet and lifestyle choices, and investigate their relationship to depression and poor mental health rates.
- Time-series analysis: The current analysis did not consider the temporal aspect of depression and mental health rates. Future research could incorporate time-series analysis to examine how depression and mental health rates change and identify seasonal or cyclical trends that may shed light on environmental or societal changes.
- Conduct qualitative research, such as interviews and focus groups, to better understand the subjective experiences of individuals living with depression and gain insights into potential risk factors that quantitative measures may not capture.
- Explore the potential role of social support networks, such as family and friends, in mitigating or exacerbating depression and poor mental health, and develop interventions to strengthen social support.


## Conclusion
In conclusion, this research project aimed to identify the factors associated with depression and poor mental health rates in the United States. The study utilized multiple linear regression models, regression trees, and ANOVA testing to analyze demographic, socioeconomic, and health-related variables. The results indicated that factors such as obesity, poor physical health, high school degree as the highest educational attainment, lack of physical activity, lack of sleep, and binge drinking were significantly associated with depression and poor mental health rates. Additionally, the project identified several limitations, including potential measurement bias, incomplete feature selection, and geographical restrictions, which may impact the accuracy of the results.
The study contributes to the growing body of literature on the social determinants of mental health and provides a basis for further research and policy interventions. The findings can assist policymakers in identifying high-risk populations and designing targeted interventions. Future research directions include exploring the role of social support networks in mitigating or exacerbating depression, conducting qualitative research to understand better the subjective experiences of individuals living with depression, and integrating genetic and biological measures into the analysis. By identifying the critical factors associated with depression and poor mental health rates, this study provides valuable insights into the underlying mechanisms of mental health disparities. It offers potential solutions for addressing this pressing public health issue.

## References
https://chronicdata.cdc.gov/500-Cities-Places/PLACES-Local-Data-for-Better-Health-Census-Tract-D/cwsq-ngmh
https://gisgeography.com/us-county-map/
https://www.ers.usda.gov/data-products/county-level-data-sets/county-level-data-sets-download-data/
https://data.census.gov/
https://www.anl.gov/dis/county-economic-impact-index
https://www.census.gov/programs-surveys/community-resilience-estimates/data/datasets.html
https://github.com/NREL/hsds-examples

GitHub Repo: https://github.com/eitanaka/DATS6101_Final_Project_Team2
